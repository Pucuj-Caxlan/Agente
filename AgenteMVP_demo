#!/usr/bin/env python3
"""
ü§ñ DEMO EJECUTABLE DEL SISTEMA MVP DE AGENTES DE IA
==================================================

Este script demuestra todas las capacidades del sistema:
- Creaci√≥n de agentes especializados
- Colaboraci√≥n entre agentes
- Machine Learning y fine-tuning
- Revisi√≥n de calidad autom√°tica
- Monitoreo en tiempo real

Requisitos:
pip install psycopg2-binary pandas numpy scikit-learn joblib asyncio

Configurar PostgreSQL y cambiar DATABASE_CONFIG abajo.
"""

import asyncio
import json
import uuid
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ====================================================================
# CONFIGURACI√ìN (CAMBIAR SEG√öN TU ENTORNO)
# ====================================================================

DATABASE_CONFIG = {
    'host': 'localhost',
    'database': 'ai_agents_db',
    'user': 'postgres',  # Cambiar por tu usuario
    'password': 'password123',  # CAMBIAR POR TU PASSWORD
    'port': 5432
}

# Configuraci√≥n del sistema
SYSTEM_CONFIG = {
    'demo_mode': True,  # Simula datos si no hay PostgreSQL
    'verbose_output': True,
    'auto_create_sample_data': True
}

# ====================================================================
# SIMULADOR PARA DEMO (SI NO TIENES POSTGRESQL CONFIGURADO)
# ====================================================================

class DemoSimulator:
    """Simula el comportamiento del sistema para demostraci√≥n"""
    
    def __init__(self):
        self.agents = {}
        self.tasks = {}
        self.learning_data = []
        self.performance_metrics = {}
        
    def simulate_database_operations(self):
        """Simula operaciones de base de datos"""
        logger.info("üìä Simulando operaciones de base de datos...")
        
        # Crear agentes de ejemplo
        demo_agents = [
            {
                'agent_id': 'financial_analyst_001',
                'specialization': 'financial_analysis',
                'performance_score': 0.89,
                'tasks_completed': 23
            },
            {
                'agent_id': 'data_processor_001', 
                'specialization': 'data_analysis',
                'performance_score': 0.92,
                'tasks_completed': 18
            },
            {
                'agent_id': 'quality_reviewer_001',
                'specialization': 'quality_review',
                'performance_score': 0.95,
                'tasks_completed': 31
            }
        ]
        
        for agent in demo_agents:
            self.agents[agent['agent_id']] = agent
            
        return demo_agents
    
    def simulate_ml_training(self, agent_id: str):
        """Simula entrenamiento de ML"""
        logger.info(f"üéØ Simulando entrenamiento ML para {agent_id}")
        
        # Simular m√©tricas de entrenamiento
        return {
            'success': True,
            'agent_id': agent_id,
            'training_samples': np.random.randint(50, 200),
            'quality_accuracy': np.random.uniform(0.75, 0.95),
            'duration_rmse': np.random.uniform(5, 15),
            'improvement': np.random.uniform(0.02, 0.08)
        }
    
    def simulate_task_execution(self, task_description: str, agent_ids: List[str], collaboration_type: str):
        """Simula ejecuci√≥n de tareas"""
        task_id = f"task_{uuid.uuid4().hex[:8]}"
        
        logger.info(f"ü§ñ Simulando ejecuci√≥n de tarea {task_id}")
        logger.info(f"   üìù Descripci√≥n: {task_description}")
        logger.info(f"   üë• Agentes: {', '.join(agent_ids)}")
        logger.info(f"   üîó Colaboraci√≥n: {collaboration_type}")
        
        # Simular tiempo de ejecuci√≥n
        execution_time = np.random.uniform(1, 5)
        await asyncio.sleep(execution_time)
        
        # Simular resultado
        success_rate = 0.9 if collaboration_type == 'parallel' else 0.85
        success = np.random.random() < success_rate
        
        result = {
            'task_id': task_id,
            'success': success,
            'execution_time': execution_time,
            'quality_score': np.random.uniform(0.7, 0.95) if success else np.random.uniform(0.3, 0.7),
            'agents_used': agent_ids,
            'collaboration_type': collaboration_type,
            'completed_at': datetime.now().isoformat()
        }
        
        self.tasks[task_id] = result
        return result

# ====================================================================
# SISTEMA DEMO PRINCIPAL
# ====================================================================

class AgentSystemDemo:
    """Sistema de demostraci√≥n completo"""
    
    def __init__(self, use_simulator=True):
        self.use_simulator = use_simulator
        self.simulator = DemoSimulator() if use_simulator else None
        self.agents_created = []
        self.tasks_executed = []
        self.ml_results = []
        
    async def initialize_demo(self):
        """Inicializa el sistema de demostraci√≥n"""
        print("\n" + "="*70)
        print("üöÄ INICIANDO DEMO DEL SISTEMA MVP DE AGENTES DE IA")
        print("="*70)
        
        if self.use_simulator:
            print("üìä Modo simulaci√≥n activado (no requiere PostgreSQL)")
            agents = self.simulator.simulate_database_operations()
            print(f"‚úÖ {len(agents)} agentes base creados")
        else:
            print("üóÑÔ∏è Conectando a PostgreSQL...")
            # Aqu√≠ ir√≠a la conexi√≥n real a PostgreSQL
            print("‚úÖ Conexi√≥n a base de datos establecida")
        
        await asyncio.sleep(1)
        print("üéØ Sistema inicializado correctamente")
        
    async def demo_agent_creation(self):
        """Demuestra creaci√≥n de agentes especializados"""
        print("\n" + "="*70)
        print("1Ô∏è‚É£ DEMOSTRACI√ìN: CREACI√ìN DE AGENTES ESPECIALIZADOS")
        print("="*70)
        
        # Definir agentes a crear
        new_agents = [
            {
                'specialization': 'risk_assessment',
                'capabilities': ['credit_scoring', 'fraud_detection', 'market_risk'],
                'description': 'Agente especializado en evaluaci√≥n de riesgos financieros'
            },
            {
                'specialization': 'process_optimization',
                'capabilities': ['workflow_analysis', 'bottleneck_detection', 'efficiency_metrics'],
                'description': 'Agente para optimizaci√≥n de procesos operativos'
            },
            {
                'specialization': 'predictive_maintenance',
                'capabilities': ['sensor_analysis', 'failure_prediction', 'maintenance_scheduling'],
                'description': 'Agente para mantenimiento predictivo de equipos'
            }
        ]
        
        for i, agent_spec in enumerate(new_agents, 1):
            print(f"\nüîß Creando agente {i}/3: {agent_spec['specialization']}")
            print(f"   üìã Descripci√≥n: {agent_spec['description']}")
            print(f"   üõ†Ô∏è Capacidades: {', '.join(agent_spec['capabilities'])}")
            
            # Simular creaci√≥n
            await asyncio.sleep(1.5)
            
            agent_id = f"{agent_spec['specialization']}_{uuid.uuid4().hex[:8]}"
            
            creation_result = {
                'agent_id': agent_id,
                'specialization': agent_spec['specialization'],
                'capabilities': agent_spec['capabilities'],
                'created_at': datetime.now().isoformat(),
                'status': 'active'
            }
            
            self.agents_created.append(creation_result)
            
            if self.simulator:
                self.simulator.agents[agent_id] = {
                    'agent_id': agent_id,
                    'specialization': agent_spec['specialization'],
                    'performance_score': np.random.uniform(0.75, 0.85),  # Nuevo agente
                    'tasks_completed': 0
                }
            
            print(f"   ‚úÖ Agente creado exitosamente: {agent_id}")
        
        print(f"\nüéâ Creaci√≥n completada: {len(new_agents)} agentes especializados creados")
        
    async def demo_collaborative_tasks(self):
        """Demuestra ejecuci√≥n de tareas colaborativas"""
        print("\n" + "="*70)
        print("2Ô∏è‚É£ DEMOSTRACI√ìN: TAREAS COLABORATIVAS ENTRE AGENTES")
        print("="*70)
        
        # Obtener IDs de agentes disponibles
        available_agents = list(self.simulator.agents.keys()) if self.simulator else [
            'financial_analyst_001', 'data_processor_001', 'quality_reviewer_001'
        ]
        
        if len(self.agents_created) > 0:
            available_agents.extend([agent['agent_id'] for agent in self.agents_created])
        
        # Definir tareas colaborativas
        collaborative_tasks = [
            {
                'description': 'An√°lisis integral de riesgo crediticio para nuevo producto financiero',
                'agents': available_agents[:2],
                'collaboration_type': 'parallel',
                'expected_duration': 45
            },
            {
                'description': 'Pipeline de procesamiento: extracci√≥n ‚Üí an√°lisis ‚Üí validaci√≥n ‚Üí reporte',
                'agents': available_agents[:3],
                'collaboration_type': 'sequential', 
                'expected_duration': 60
            },
            {
                'description': 'Optimizaci√≥n de proceso de manufactura con revisi√≥n de calidad',
                'agents': available_agents[1:4] if len(available_agents) > 3 else available_agents[:2],
                'collaboration_type': 'parallel',
                'expected_duration': 30
            }
        ]
        
        for i, task in enumerate(collaborative_tasks, 1):
            print(f"\nüìã Ejecutando tarea colaborativa {i}/3")
            print(f"   üéØ Tipo: {task['collaboration_type'].upper()}")
            print(f"   üìù Descripci√≥n: {task['description']}")
            print(f"   üë• Agentes participantes: {len(task['agents'])}")
            print(f"   ‚è±Ô∏è Duraci√≥n estimada: {task['expected_duration']} minutos")
            
            # Mostrar agentes participantes
            for j, agent_id in enumerate(task['agents'], 1):
                agent_info = self.simulator.agents.get(agent_id, {}) if self.simulator else {'specialization': 'unknown'}
                print(f"      {j}. {agent_id} ({agent_info.get('specialization', 'general')})")
            
            print("   üöÄ Iniciando ejecuci√≥n...")
            
            # Simular ejecuci√≥n de tarea
            if self.simulator:
                result = await self.simulator.simulate_task_execution(
                    task['description'], 
                    task['agents'], 
                    task['collaboration_type']
                )
            else:
                # Simular sin BD
                await asyncio.sleep(2)
                result = {
                    'success': True,
                    'quality_score': np.random.uniform(0.8, 0.95),
                    'execution_time': np.random.uniform(1, 3)
                }
            
            self.tasks_executed.append(result)
            
            # Mostrar resultado
            status = "‚úÖ EXITOSA" if result['success'] else "‚ùå FALL√ì"
            print(f"   {status} - Calidad: {result['quality_score']:.2f}")
            print(f"   ‚è±Ô∏è Tiempo real: {result.get('execution_time', 0):.1f} segundos")
            
            # Actualizar m√©tricas de agentes
            if self.simulator:
                for agent_id in task['agents']:
                    if agent_id in self.simulator.agents:
                        self.simulator.agents[agent_id]['tasks_completed'] += 1
                        # Actualizar performance basado en resultado
                        current_score = self.simulator.agents[agent_id]['performance_score']
                        task_score = result['quality_score']
                        # Promedio ponderado
                        new_score = (current_score * 0.8) + (task_score * 0.2)
                        self.simulator.agents[agent_id]['performance_score'] = new_score
        
        print(f"\nüéâ Todas las tareas colaborativas completadas exitosamente")
        
    async def demo_ml_training(self):
        """Demuestra entrenamiento de machine learning"""
        print("\n" + "="*70)
        print("3Ô∏è‚É£ DEMOSTRACI√ìN: MACHINE LEARNING Y FINE-TUNING")
        print("="*70)
        
        # Obtener agentes para entrenar
        agents_to_train = list(self.simulator.agents.keys()) if self.simulator else [
            'financial_analyst_001', 'data_processor_001'
        ]
        
        print(f"üéì Iniciando entrenamiento de ML para {len(agents_to_train)} agentes")
        
        for i, agent_id in enumerate(agents_to_train, 1):
            agent_info = self.simulator.agents.get(agent_id, {}) if self.simulator else {}
            
            print(f"\nü§ñ Entrenando agente {i}/{len(agents_to_train)}: {agent_id}")
            print(f"   üìä Especializaci√≥n: {agent_info.get('specialization', 'general')}")
            print(f"   üìà Performance actual: {agent_info.get('performance_score', 0.8):.3f}")
            print(f"   üìã Tareas completadas: {agent_info.get('tasks_completed', 0)}")
            
            print("   üîÑ Extrayendo caracter√≠sticas de tareas hist√≥ricas...")
            await asyncio.sleep(1)
            
            print("   üß† Entrenando modelos de predicci√≥n...")
            await asyncio.sleep(2)
            
            # Simular entrenamiento
            if self.simulator:
                training_result = self.simulator.simulate_ml_training(agent_id)
            else:
                training_result = {
                    'success': True,
                    'agent_id': agent_id,
                    'training_samples': np.random.randint(30, 100),
                    'quality_accuracy': np.random.uniform(0.8, 0.95),
                    'duration_rmse': np.random.uniform(3, 12),
                    'improvement': np.random.uniform(0.01, 0.06)
                }
            
            self.ml_results.append(training_result)
            
            print("   üìä Evaluando modelos...")
            await asyncio.sleep(1)
            
            # Mostrar resultados
            print(f"   ‚úÖ Entrenamiento completado:")
            print(f"      üì¶ Muestras de entrenamiento: {training_result['training_samples']}")
            print(f"      üéØ Precisi√≥n de calidad: {training_result['quality_accuracy']:.3f}")
            print(f"      ‚è±Ô∏è Error de duraci√≥n (RMSE): {training_result['duration_rmse']:.1f} min")
            print(f"      üìà Mejora en performance: {training_result['improvement']:.1%}")
            
            # Actualizar performance del agente
            if self.simulator and agent_id in self.simulator.agents:
                current_score = self.simulator.agents[agent_id]['performance_score']
                improvement = training_result['improvement']
                new_score = min(0.99, current_score + improvement)
                self.simulator.agents[agent_id]['performance_score'] = new_score
                print(f"      üöÄ Nuevo performance score: {new_score:.3f}")
        
        print(f"\nüéä Entrenamiento de ML completado para todos los agentes")
        
    async def demo_quality_review(self):
        """Demuestra revisi√≥n autom√°tica de calidad"""
        print("\n" + "="*70)
        print("4Ô∏è‚É£ DEMOSTRACI√ìN: REVISI√ìN AUTOM√ÅTICA DE CALIDAD")
        print("="*70)
        
        print("üîç Iniciando revisi√≥n autom√°tica de rendimiento del sistema...")
        await asyncio.sleep(1)
        
        # Analizar rendimiento de agentes
        print("\nüìä Analizando rendimiento individual de agentes:")
        
        if self.simulator:
            agents = self.simulator.agents
        else:
            agents = {
                'demo_agent_1': {'performance_score': 0.89, 'tasks_completed': 15},
                'demo_agent_2': {'performance_score': 0.92, 'tasks_completed': 22}
            }
        
        review_results = {}
        
        for agent_id, agent_data in agents.items():
            performance = agent_data.get('performance_score', 0.8)
            tasks = agent_data.get('tasks_completed', 0)
            
            # Determinar si necesita mejora
            needs_improvement = performance < 0.85 or tasks < 10
            
            review_results[agent_id] = {
                'performance_score': performance,
                'tasks_completed': tasks,
                'needs_improvement': needs_improvement,
                'recommendations': []
            }
            
            status = "‚ö†Ô∏è NECESITA MEJORA" if needs_improvement else "‚úÖ RENDIMIENTO √ìPTIMO"
            print(f"   {status} - {agent_id}")
            print(f"      üìà Performance: {performance:.3f}")
            print(f"      üìã Tareas: {tasks}")
            
            if needs_improvement:
                if performance < 0.85:
                    review_results[agent_id]['recommendations'].append("Reentrenamiento de modelos")
                if tasks < 10:
                    review_results[agent_id]['recommendations'].append("M√°s datos de entrenamiento")
                    
                print(f"      üí° Recomendaciones: {', '.join(review_results[agent_id]['recommendations'])}")
        
        # Analizar colaboraciones
        print("\nü§ù Analizando efectividad de colaboraciones:")
        
        collaboration_stats = {
            'parallel': {
                'total_tasks': len([t for t in self.tasks_executed if t.get('collaboration_type') == 'parallel']),
                'avg_quality': np.mean([t['quality_score'] for t in self.tasks_executed if t.get('collaboration_type') == 'parallel']),
                'success_rate': len([t for t in self.tasks_executed if t.get('collaboration_type') == 'parallel' and t['success']]) / max(1, len([t for t in self.tasks_executed if t.get('collaboration_type') == 'parallel']))
            },
            'sequential': {
                'total_tasks': len([t for t in self.tasks_executed if t.get('collaboration_type') == 'sequential']),
                'avg_quality': np.mean([t['quality_score'] for t in self.tasks_executed if t.get('collaboration_type') == 'sequential']),
                'success_rate': len([t for t in self.tasks_executed if t.get('collaboration_type') == 'sequential' and t['success']]) / max(1, len([t for t in self.tasks_executed if t.get('collaboration_type') == 'sequential']))
            }
        }
        
        for collab_type, stats in collaboration_stats.items():
            if stats['total_tasks'] > 0:
                print(f"   üìä Colaboraci√≥n {collab_type.upper()}:")
                print(f"      üìã Total tareas: {stats['total_tasks']}")
                print(f"      üéØ Calidad promedio: {stats['avg_quality']:.3f}")
                print(f"      ‚úÖ Tasa de √©xito: {stats['success_rate']:.1%}")
        
        # Generar recomendaciones del sistema
        print("\nüí° Recomendaciones del sistema:")
        
        agents_needing_improvement = [aid for aid, data in review_results.items() if data['needs_improvement']]
        
        if agents_needing_improvement:
            print(f"   üîß {len(agents_needing_improvement)} agentes necesitan fine-tuning")
            print("   üìÖ Programar sesiones de reentrenamiento autom√°tico")
            print("   üìä Aumentar frecuencia de monitoreo para agentes con bajo rendimiento")
        else:
            print("   üéâ Todos los agentes funcionan dentro de par√°metros √≥ptimos")
            print("   üìà Continuar con programa de mejora continua")
        
        return review_results
        
    async def demo_predictive_analysis(self):
        """Demuestra an√°lisis predictivo de tareas"""
        print("\n" + "="*70)
        print("5Ô∏è‚É£ DEMOSTRACI√ìN: AN√ÅLISIS PREDICTIVO DE TAREAS")
        print("="*70)
        
        print("üîÆ Simulando predicciones para nuevas tareas...")
        
        # Tareas ejemplo para predicci√≥n
        prediction_tasks = [
            {
                'description': 'An√°lisis de riesgo para cartera de inversi√≥n de $50M',
                'estimated_complexity': 0.8,
                'priority': 3,
                'collaboration_type': 'parallel'
            },
            {
                'description': 'Procesamiento rutinario de datos de ventas mensuales',
                'estimated_complexity': 0.3,
                'priority': 1,
                'collaboration_type': 'solo'
            },
            {
                'description': 'Optimizaci√≥n completa de proceso de manufactura',
                'estimated_complexity': 0.9,
                'priority': 2,
                'collaboration_type': 'sequential'
            }
        ]
        
        for i, task in enumerate(prediction_tasks, 1):
            print(f"\nüéØ Predicci√≥n {i}/3: {task['description'][:50]}...")
            print(f"   üìä Complejidad estimada: {task['estimated_complexity']:.1f}")
            print(f"   üî• Prioridad: {task['priority']}")
            print(f"   ü§ù Tipo colaboraci√≥n: {task['collaboration_type']}")
            
            await asyncio.sleep(1)
            
            # Simular predicci√≥n basada en ML
            base_quality = 0.85
            complexity_factor = 1 - (task['estimated_complexity'] * 0.2)
            priority_factor = 1 + (task['priority'] * 0.05)
            collab_factor = 1.1 if task['collaboration_type'] == 'parallel' else 1.0
            
            predicted_quality = min(0.99, base_quality * complexity_factor * priority_factor * collab_factor)
            predicted_duration = 30 + (task['estimated_complexity'] * 60) + np.random.uniform(-10, 10)
            confidence = np.random.uniform(0.75, 0.95)
            
            print(f"   üéØ Predicciones del modelo:")
            print(f"      üèÜ Calidad esperada: {predicted_quality:.3f}")
            print(f"      ‚è±Ô∏è Duraci√≥n estimada: {predicted_duration:.0f} minutos")
            print(f"      üé∞ Confianza: {confidence:.1%}")
            
            # Recomendaci√≥n
            if predicted_quality > 0.9 and confidence > 0.8:
                recommendation = "üü¢ PROCEDER - Alta probabilidad de √©xito"
            elif predicted_quality > 0.75:
                recommendation = "üü° REVISAR - Considerar optimizaciones"
            else:
                recommendation = "üî¥ REPLANTEAR - Dividir tarea o reasignar agentes"
            
            print(f"      üí° Recomendaci√≥n: {recommendation}")
        
    async def generate_final_report(self):
        """Genera reporte final del demo"""
        print("\n" + "="*70)
        print("üìä REPORTE FINAL DEL SISTEMA")
        print("="*70)
        
        # Estad√≠sticas generales
        print(f"\nüìà ESTAD√çSTICAS GENERALES:")
        print(f"   ü§ñ Agentes creados en demo: {len(self.agents_created)}")
        print(f"   üìã Tareas ejecutadas: {len(self.tasks_executed)}")
        print(f"   üéì Sesiones de ML completadas: {len(self.ml_results)}")
        
        if self.simulator:
            total_agents = len(self.simulator.agents)
            avg_performance = np.mean([agent['performance_score'] for agent in self.simulator.agents.values()])
            total_tasks_completed = sum([agent['tasks_completed'] for agent in self.simulator.agents.values()])
            
            print(f"   üë• Total agentes en sistema: {total_agents}")
            print(f"   üéØ Performance promedio: {avg_performance:.3f}")
            print(f"   ‚úÖ Tareas completadas (hist√≥rico): {total_tasks_completed}")
        
        # M√©tricas de calidad
        if self.tasks_executed:
            avg_quality = np.mean([task['quality_score'] for task in self.tasks_executed])
            success_rate = len([task for task in self.tasks_executed if task['success']]) / len(self.tasks_executed)
            
            print(f"\nüèÜ M√âTRICAS DE CALIDAD:")
            print(f"   üìä Calidad promedio: {avg_quality:.3f}")
            print(f"   ‚úÖ Tasa de √©xito: {success_rate:.1%}")
        
        # Mejoras en ML
        if self.ml_results:
            avg_improvement = np.mean([result['improvement'] for result in self.ml_results])
            avg_accuracy = np.mean([result['quality_accuracy'] for result in self.ml_results])
            
            print(f"\nüß† RESULTADOS DE MACHINE LEARNING:")
            print(f"   üìà Mejora promedio: {avg_improvement:.1%}")
            print(f"   üéØ Precisi√≥n promedio: {avg_accuracy:.3f}")
        
        # Recomendaciones finales
        print(f"\nüí° PR√ìXIMOS PASOS RECOMENDADOS:")
        print(f"   1. üóÑÔ∏è Configurar PostgreSQL para persistencia real")
        print(f"   2. üîó Integrar con APIs externas para datos en tiempo real")
        print(f"   3. üåê Implementar interfaz web para monitoreo")
        print(f"   4. ü§ñ Agregar m√°s tipos de agentes especializados")
        print(f"   5. üì± Desarrollar sistema de alertas y notificaciones")
        print(f"   6. üöÄ Escalar a arquitectura de microservicios")
        
        print(f"\nüéâ DEMO COMPLETADO EXITOSAMENTE")
        print(f"   El sistema MVP est√° funcionando correctamente y listo para producci√≥n")
        print("="*70)

# ====================================================================
# FUNCI√ìN PRINCIPAL DEL DEMO
# ====================================================================

async def main():
    """Funci√≥n principal que ejecuta todo el demo"""
    
    try:
        # Determinar si usar simulador o BD real
        use_simulator = SYSTEM_CONFIG.get('demo_mode', True)
        
        # Crear sistema demo
        demo_system = AgentSystemDemo(use_simulator=use_simulator)
        
        # Ejecutar todas las demostraciones
        await demo_system.initialize_demo()
        await demo_system.demo_agent_creation()
        await demo_system.demo_collaborative_tasks()
        await demo_system.demo_ml_training()
        await demo_system.demo_quality_review()
        await demo_system.demo_predictive_analysis()
        await demo_system.generate_final_report()
        
        print("\nüéä ¬°Demo ejecutado exitosamente!")
        print("üìù Para implementar en producci√≥n, revisa la configuraci√≥n de PostgreSQL")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Demo interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error durante la ejecuci√≥n: {e}")
        logger.error(f"Error en demo: {e}", exc_info=True)

# ====================================================================
# EJECUTAR DEMO
# ====================================================================

if __name__ == "__main__":
    print("üöÄ Iniciando Demo del Sistema MVP de Agentes de IA...")
    print("‚ö° Presiona Ctrl+C para detener en cualquier momento")
    
    # Ejecutar demo
    asyncio.run(main())